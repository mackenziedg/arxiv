{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine similarity\n",
    "\n",
    "First we read in the data and process the abstracts by removing `NaN`s, converting to lowercase, and removing stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/full_arxiv_cs_clean.csv\", index_col=\"Unnamed: 0\", low_memory=False)\n",
    "selected = df[~df.abstract.isnull()][['abstract', 'id']]\n",
    "clean_abstracts = selected.abstract.str.lower()\n",
    "clean_abstracts = clean_abstracts.str.replace(r\"[.()$,:;\\\"%{}\\-\\\\/<>+=_~'^]\", \" \")\n",
    "clean_abstracts = clean_abstracts.str.replace(r\" {2,}\", \" \")\n",
    "clean_abstracts = clean_abstracts.apply(lambda x: [i for i in x.strip().split()\n",
    "                                                   if i not in stopwords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can generate word counts for each document with a Python `Counter` like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_counts = clean_abstracts.apply(lambda x: Counter(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the full list of words in all documents, we can go through each `Counter` and add the keys to a `set` of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set()\n",
    "\n",
    "def add_words(s, doc):\n",
    "    [s.add(i) for i in doc.keys()]\n",
    "    \n",
    "ca_counts.apply(lambda x: add_words(unique_words, x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convert the `set` to a `list` to finalize the (arbitrary) order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(a, b):\n",
    "    \"\"\"Takes two sparse vectors and finds their dot products.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a, b -- Sparse vectors represented as Python Counters\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    c -- Dot product of `a` and `b`\n",
    "    \"\"\"\n",
    "    c = 0\n",
    "    for k in a.keys() & b.keys():\n",
    "        c += a[k] * b[k]\n",
    "    return c\n",
    "\n",
    "def norm(a):\n",
    "    \"\"\"Finds the L2 norm of a sparse vector.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a -- Sparse vector represented as a Python Counter\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    b -- Norm of `a`\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(np.fromiter(a.values(), dtype=int), 2)\n",
    "\n",
    "def cosine_similarity(doc1, doc2):\n",
    "    \"\"\"Finds the cosine similarity between two documents.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    doc1, doc2 -- Sparse vectors of word counts represented as Python Counters\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Cosine similarity between `doc1` and `doc2`\n",
    "    \"\"\"\n",
    "    return dot(doc1, doc2)/(norm(doc1)*norm(doc2))\n",
    "\n",
    "def cosine_distance(doc1, doc2):\n",
    "    \"\"\"Finds the cosine distance between two documents.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    doc1, doc2 -- Sparse vectors of word counts represented as Python Counters\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Cosine distance between `doc1` and `doc2`\n",
    "    \"\"\"\n",
    "    return 1-cosine_similarity(doc1, doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(doc, n=100):\n",
    "    \"\"\"Returns the n most similar documents.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    doc -- Document of interest\n",
    "    n -- Number of results to return (optional)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    similarities -- A size-n vector of document similarities, ignoring the same document\"\"\"\n",
    "    similarities = ca_counts.apply(lambda x: cosine_similarity(doc, x))\n",
    "    return similarities.sort_values(ascending=False)[1:(1+n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running this on the full data set would be ~160 Gb\n",
    "\n",
    "# similarities = dict()\n",
    "\n",
    "# def get_similarities(row):\n",
    "#     id_ = row['index']\n",
    "#     if id_ % 100 == 0:\n",
    "#         print(id_)\n",
    "#     similarities.update({id_: dict()})\n",
    "#     ca_counts[id_:1000].reset_index().apply(\n",
    "#         lambda doc: similarities[id_].update(\n",
    "#             {doc['index']: cosine_similarity(row.abstract, doc.abstract)}\n",
    "#         ), axis=1)\n",
    "        \n",
    "# ca_counts[:1000].reset_index().apply(get_similarities, axis=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
